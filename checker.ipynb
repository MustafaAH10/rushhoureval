{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rush Hour Model Response Evaluator\n",
    "# Comprehensive evaluation system for assessing model solutions\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Optional, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the solver functions from the original generator\n",
    "# (You'll need to ensure the original file is importable or copy the necessary functions)\n",
    "\n",
    "GRID_SIZE = 3\n",
    "\n",
    "class RushHourEvaluator:\n",
    "    def __init__(self, dataset_path: str = \"data\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.results = []\n",
    "        \n",
    "    def parse_solution_from_response(self, response: str) -> Optional[List[str]]:\n",
    "        \"\"\"Extract solution from model response with multiple parsing strategies\"\"\"\n",
    "        \n",
    "        # Strategy 1: Look for <solution> tags\n",
    "        solution_match = re.search(r'<solution>(.*?)</solution>', response, re.DOTALL | re.IGNORECASE)\n",
    "        if solution_match:\n",
    "            solution_text = solution_match.group(1).strip()\n",
    "        else:\n",
    "            # Strategy 2: Look for step patterns in the entire response\n",
    "            solution_text = response\n",
    "        \n",
    "        # Extract step lines\n",
    "        step_pattern = r'Step\\s+\\d+:\\s*([A-Z]\\d*)\\s*\\[(\\d+),(\\d+)\\]\\s*->\\s*\\[(\\d+),(\\d+)\\]'\n",
    "        matches = re.findall(step_pattern, solution_text, re.IGNORECASE)\n",
    "        \n",
    "        if not matches:\n",
    "            return None\n",
    "            \n",
    "        moves = []\n",
    "        for match in matches:\n",
    "            piece, start_row, start_col, end_row, end_col = match\n",
    "            moves.append({\n",
    "                'piece': piece.upper(),\n",
    "                'start': (int(start_row), int(start_col)),\n",
    "                'end': (int(end_row), int(end_col))\n",
    "            })\n",
    "        \n",
    "        return moves\n",
    "    \n",
    "    def load_puzzle_data(self, puzzle_folder: str) -> Dict:\n",
    "        \"\"\"Load puzzle data including initial state and reference solution\"\"\"\n",
    "        puzzle_data = {}\n",
    "        \n",
    "        # Load puzzle grid from solution.txt metadata\n",
    "        solution_file = os.path.join(puzzle_folder, \"solution.txt\")\n",
    "        if os.path.exists(solution_file):\n",
    "            with open(solution_file, 'r') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            # Extract exit position\n",
    "            exit_match = re.search(r'Exit position: \\[(\\d+),(\\d+)\\]', content)\n",
    "            if exit_match:\n",
    "                puzzle_data['exit_pos'] = (int(exit_match.group(1)), int(exit_match.group(2)))\n",
    "            \n",
    "            # Extract reference solution moves\n",
    "            solution_lines = []\n",
    "            in_solution = False\n",
    "            for line in content.split('\\n'):\n",
    "                if line.strip() == \"Solution:\":\n",
    "                    in_solution = True\n",
    "                    continue\n",
    "                if in_solution and line.strip().startswith(\"Step\"):\n",
    "                    solution_lines.append(line.strip())\n",
    "            \n",
    "            puzzle_data['reference_moves'] = self.parse_solution_text(solution_lines)\n",
    "            puzzle_data['optimal_length'] = len(puzzle_data['reference_moves'])\n",
    "        \n",
    "        return puzzle_data\n",
    "    \n",
    "    def parse_solution_text(self, solution_lines: List[str]) -> List[Dict]:\n",
    "        \"\"\"Parse solution text lines into move format\"\"\"\n",
    "        moves = []\n",
    "        for line in solution_lines:\n",
    "            match = re.search(r'Step\\s+\\d+:\\s*([A-Z]\\d*)\\s*\\[(\\d+),(\\d+)\\]\\s*->\\s*\\[(\\d+),(\\d+)\\]', line)\n",
    "            if match:\n",
    "                piece, start_row, start_col, end_row, end_col = match.groups()\n",
    "                moves.append({\n",
    "                    'piece': piece.upper(),\n",
    "                    'start': (int(start_row), int(start_col)),\n",
    "                    'end': (int(end_row), int(end_col))\n",
    "                })\n",
    "        return moves\n",
    "    \n",
    "    def reconstruct_initial_grid(self, puzzle_data: Dict) -> List[List[str]]:\n",
    "        \"\"\"Reconstruct initial grid state from reference solution by working backwards\"\"\"\n",
    "        if not puzzle_data.get('reference_moves'):\n",
    "            return None\n",
    "            \n",
    "        # Start with final state and work backwards\n",
    "        grid = [['.' for _ in range(GRID_SIZE)] for _ in range(GRID_SIZE)]\n",
    "        \n",
    "        # Place car at exit in final state\n",
    "        exit_pos = puzzle_data['exit_pos']\n",
    "        exit_row, exit_col = exit_pos[0] - 1, exit_pos[1] - 1  # Convert to 0-indexed\n",
    "        grid[exit_row][exit_col] = 'C'\n",
    "        \n",
    "        # Work backwards through moves\n",
    "        moves = puzzle_data['reference_moves'][::-1]  # Reverse order\n",
    "        pieces_seen = {'C'}\n",
    "        \n",
    "        for move in moves:\n",
    "            piece = move['piece']\n",
    "            pieces_seen.add(piece)\n",
    "            # In reverse: end -> start becomes start -> end\n",
    "            start_pos = (move['end'][0] - 1, move['end'][1] - 1)  # Convert to 0-indexed\n",
    "            end_pos = (move['start'][0] - 1, move['start'][1] - 1)\n",
    "            \n",
    "            # Move piece from start to end position\n",
    "            grid[start_pos[0]][start_pos[1]] = '.'\n",
    "            grid[end_pos[0]][end_pos[1]] = piece\n",
    "        \n",
    "        # Fill remaining empty cells with blockers if needed\n",
    "        empty_count = sum(row.count('.') for row in grid)\n",
    "        if empty_count > 1:  # Should have exactly 1 empty cell\n",
    "            # This suggests there are additional blockers not involved in solution\n",
    "            # We'll need to infer their positions or load from image analysis\n",
    "            pass\n",
    "            \n",
    "        return grid\n",
    "    \n",
    "    def simulate_moves(self, initial_grid: List[List[str]], moves: List[Dict], \n",
    "                      exit_pos: Tuple[int, int]) -> Tuple[bool, str, List[List[List[str]]]]:\n",
    "        \"\"\"Simulate moves and check validity\"\"\"\n",
    "        if not initial_grid or not moves:\n",
    "            return False, \"No grid or moves provided\", []\n",
    "        \n",
    "        grid = [row[:] for row in initial_grid]  # Deep copy\n",
    "        states = [grid]\n",
    "        exit_row, exit_col = exit_pos[0] - 1, exit_pos[1] - 1  # Convert to 0-indexed\n",
    "        \n",
    "        for i, move in enumerate(moves):\n",
    "            piece = move['piece']\n",
    "            start_row, start_col = move['start'][0] - 1, move['start'][1] - 1  # Convert to 0-indexed\n",
    "            end_row, end_col = move['end'][0] - 1, move['end'][1] - 1\n",
    "            \n",
    "            # Validate move\n",
    "            if not (0 <= start_row < GRID_SIZE and 0 <= start_col < GRID_SIZE):\n",
    "                return False, f\"Step {i+1}: Start position out of bounds\", states\n",
    "            \n",
    "            if not (0 <= end_row < GRID_SIZE and 0 <= end_col < GRID_SIZE):\n",
    "                return False, f\"Step {i+1}: End position out of bounds\", states\n",
    "            \n",
    "            if grid[start_row][start_col] != piece:\n",
    "                return False, f\"Step {i+1}: Piece {piece} not at start position [{move['start'][0]},{move['start'][1]}]\", states\n",
    "            \n",
    "            if grid[end_row][end_col] != '.':\n",
    "                return False, f\"Step {i+1}: End position [{move['end'][0]},{move['end'][1]}] is occupied\", states\n",
    "            \n",
    "            # Check if move is adjacent (only one square)\n",
    "            if abs(start_row - end_row) + abs(start_col - end_col) != 1:\n",
    "                return False, f\"Step {i+1}: Move is not adjacent (must be exactly 1 square)\", states\n",
    "            \n",
    "            # Apply move\n",
    "            grid[start_row][start_col] = '.'\n",
    "            grid[end_row][end_col] = piece\n",
    "            states.append([row[:] for row in grid])\n",
    "        \n",
    "        # Check if solved\n",
    "        if grid[exit_row][exit_col] == 'C':\n",
    "            return True, \"Solution correct!\", states\n",
    "        else:\n",
    "            car_pos = None\n",
    "            for r in range(GRID_SIZE):\n",
    "                for c in range(GRID_SIZE):\n",
    "                    if grid[r][c] == 'C':\n",
    "                        car_pos = (r+1, c+1)  # Convert to 1-indexed\n",
    "                        break\n",
    "            return False, f\"Car not at target. Car at [{car_pos[0]},{car_pos[1]}], target at [{exit_pos[0]},{exit_pos[1]}]\", states\n",
    "    \n",
    "    def calculate_progress_score(self, initial_grid: List[List[str]], moves: List[Dict], \n",
    "                                exit_pos: Tuple[int, int]) -> Dict:\n",
    "        \"\"\"Calculate progress made towards solution even if not complete\"\"\"\n",
    "        if not initial_grid:\n",
    "            return {\"progress_score\": 0, \"details\": \"No initial grid\"}\n",
    "        \n",
    "        # Find initial car position\n",
    "        initial_car_pos = None\n",
    "        for r in range(GRID_SIZE):\n",
    "            for c in range(GRID_SIZE):\n",
    "                if initial_grid[r][c] == 'C':\n",
    "                    initial_car_pos = (r, c)\n",
    "                    break\n",
    "        \n",
    "        if not initial_car_pos:\n",
    "            return {\"progress_score\": 0, \"details\": \"No car found\"}\n",
    "        \n",
    "        exit_row, exit_col = exit_pos[0] - 1, exit_pos[1] - 1  # Convert to 0-indexed\n",
    "        \n",
    "        # Calculate initial distance\n",
    "        initial_distance = abs(initial_car_pos[0] - exit_row) + abs(initial_car_pos[1] - exit_col)\n",
    "        \n",
    "        if not moves:\n",
    "            return {\n",
    "                \"progress_score\": 0,\n",
    "                \"initial_distance\": initial_distance,\n",
    "                \"final_distance\": initial_distance,\n",
    "                \"details\": \"No moves provided\"\n",
    "            }\n",
    "        \n",
    "        # Simulate valid moves to find final car position\n",
    "        grid = [row[:] for row in initial_grid]\n",
    "        valid_moves = 0\n",
    "        \n",
    "        for i, move in enumerate(moves):\n",
    "            piece = move['piece']\n",
    "            start_row, start_col = move['start'][0] - 1, move['start'][1] - 1\n",
    "            end_row, end_col = move['end'][0] - 1, move['end'][1] - 1\n",
    "            \n",
    "            # Check if move is valid\n",
    "            if (0 <= start_row < GRID_SIZE and 0 <= start_col < GRID_SIZE and\n",
    "                0 <= end_row < GRID_SIZE and 0 <= end_col < GRID_SIZE and\n",
    "                grid[start_row][start_col] == piece and\n",
    "                grid[end_row][end_col] == '.' and\n",
    "                abs(start_row - end_row) + abs(start_col - end_col) == 1):\n",
    "                \n",
    "                # Apply move\n",
    "                grid[start_row][start_col] = '.'\n",
    "                grid[end_row][end_col] = piece\n",
    "                valid_moves += 1\n",
    "            else:\n",
    "                break  # Stop at first invalid move\n",
    "        \n",
    "        # Find final car position\n",
    "        final_car_pos = None\n",
    "        for r in range(GRID_SIZE):\n",
    "            for c in range(GRID_SIZE):\n",
    "                if grid[r][c] == 'C':\n",
    "                    final_car_pos = (r, c)\n",
    "                    break\n",
    "        \n",
    "        if not final_car_pos:\n",
    "            final_car_pos = initial_car_pos\n",
    "        \n",
    "        final_distance = abs(final_car_pos[0] - exit_row) + abs(final_car_pos[1] - exit_col)\n",
    "        \n",
    "        # Calculate progress score (0-1, where 1 is solved)\n",
    "        if final_distance == 0:\n",
    "            progress_score = 1.0\n",
    "        elif initial_distance == 0:\n",
    "            progress_score = 1.0\n",
    "        else:\n",
    "            # Score based on distance reduction\n",
    "            distance_improvement = initial_distance - final_distance\n",
    "            progress_score = max(0, distance_improvement / initial_distance)\n",
    "            \n",
    "            # Bonus for valid moves\n",
    "            if valid_moves > 0:\n",
    "                progress_score += 0.1 * (valid_moves / len(moves))\n",
    "            \n",
    "            progress_score = min(1.0, progress_score)\n",
    "        \n",
    "        return {\n",
    "            \"progress_score\": progress_score,\n",
    "            \"initial_distance\": initial_distance,\n",
    "            \"final_distance\": final_distance,\n",
    "            \"valid_moves\": valid_moves,\n",
    "            \"total_moves\": len(moves),\n",
    "            \"details\": f\"Reduced distance from {initial_distance} to {final_distance}\"\n",
    "        }\n",
    "    \n",
    "    def evaluate_response(self, puzzle_folder: str, model_response: str, \n",
    "                         model_name: str = \"unknown\") -> Dict:\n",
    "        \"\"\"Comprehensive evaluation of a model response\"\"\"\n",
    "        puzzle_name = os.path.basename(puzzle_folder)\n",
    "        \n",
    "        # Load puzzle data\n",
    "        puzzle_data = self.load_puzzle_data(puzzle_folder)\n",
    "        if not puzzle_data:\n",
    "            return {\n",
    "                \"puzzle\": puzzle_name,\n",
    "                \"model\": model_name,\n",
    "                \"status\": \"ERROR\",\n",
    "                \"error\": \"Could not load puzzle data\"\n",
    "            }\n",
    "        \n",
    "        # Parse model response\n",
    "        moves = self.parse_solution_from_response(model_response)\n",
    "        \n",
    "        result = {\n",
    "            \"puzzle\": puzzle_name,\n",
    "            \"model\": model_name,\n",
    "            \"response_length\": len(model_response),\n",
    "            \"moves_found\": len(moves) if moves else 0,\n",
    "            \"optimal_length\": puzzle_data.get('optimal_length', 0),\n",
    "            \"exit_position\": puzzle_data.get('exit_pos', (0, 0))\n",
    "        }\n",
    "        \n",
    "        if not moves:\n",
    "            result.update({\n",
    "                \"status\": \"PARSE_ERROR\",\n",
    "                \"correctness\": \"INVALID\",\n",
    "                \"progress_score\": 0,\n",
    "                \"error\": \"Could not parse any moves from response\"\n",
    "            })\n",
    "            return result\n",
    "        \n",
    "        # Reconstruct initial grid\n",
    "        initial_grid = self.reconstruct_initial_grid(puzzle_data)\n",
    "        if not initial_grid:\n",
    "            result.update({\n",
    "                \"status\": \"GRID_ERROR\",\n",
    "                \"correctness\": \"UNKNOWN\",\n",
    "                \"error\": \"Could not reconstruct initial grid\"\n",
    "            })\n",
    "            return result\n",
    "        \n",
    "        # Simulate moves\n",
    "        is_correct, message, states = self.simulate_moves(\n",
    "            initial_grid, moves, puzzle_data['exit_pos']\n",
    "        )\n",
    "        \n",
    "        # Calculate progress\n",
    "        progress_info = self.calculate_progress_score(\n",
    "            initial_grid, moves, puzzle_data['exit_pos']\n",
    "        )\n",
    "        \n",
    "        # Determine correctness level\n",
    "        if is_correct:\n",
    "            if len(moves) == puzzle_data['optimal_length']:\n",
    "                correctness = \"OPTIMAL\"\n",
    "            else:\n",
    "                correctness = \"CORRECT_SUBOPTIMAL\"\n",
    "        else:\n",
    "            if progress_info['valid_moves'] == 0:\n",
    "                correctness = \"INVALID\"\n",
    "            elif progress_info['progress_score'] > 0.5:\n",
    "                correctness = \"PARTIAL_GOOD\"\n",
    "            else:\n",
    "                correctness = \"PARTIAL_POOR\"\n",
    "        \n",
    "        result.update({\n",
    "            \"status\": \"EVALUATED\",\n",
    "            \"correctness\": correctness,\n",
    "            \"is_solved\": is_correct,\n",
    "            \"progress_score\": progress_info['progress_score'],\n",
    "            \"valid_moves\": progress_info['valid_moves'],\n",
    "            \"message\": message,\n",
    "            \"efficiency\": len(moves) / puzzle_data['optimal_length'] if puzzle_data['optimal_length'] > 0 else float('inf')\n",
    "        })\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def evaluate_dataset(self, responses_file: str) -> pd.DataFrame:\n",
    "        \"\"\"Evaluate all responses in a dataset\"\"\"\n",
    "        # Load responses (assuming JSON format with puzzle_name -> response mapping)\n",
    "        with open(responses_file, 'r') as f:\n",
    "            responses = json.load(f)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for puzzle_name, response_data in responses.items():\n",
    "            puzzle_folder = os.path.join(self.dataset_path, puzzle_name)\n",
    "            \n",
    "            if isinstance(response_data, dict):\n",
    "                # Multiple models\n",
    "                for model_name, response in response_data.items():\n",
    "                    result = self.evaluate_response(puzzle_folder, response, model_name)\n",
    "                    results.append(result)\n",
    "            else:\n",
    "                # Single response\n",
    "                result = self.evaluate_response(puzzle_folder, response_data)\n",
    "                results.append(result)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def generate_report(self, results_df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Generate comprehensive evaluation report\"\"\"\n",
    "        report = {}\n",
    "        \n",
    "        # Overall statistics\n",
    "        total_puzzles = len(results_df)\n",
    "        report['total_puzzles'] = total_puzzles\n",
    "        \n",
    "        # By correctness level\n",
    "        correctness_counts = results_df['correctness'].value_counts()\n",
    "        report['correctness_breakdown'] = correctness_counts.to_dict()\n",
    "        \n",
    "        # Success rates\n",
    "        optimal_rate = (correctness_counts.get('OPTIMAL', 0) / total_puzzles) * 100\n",
    "        correct_rate = ((correctness_counts.get('OPTIMAL', 0) + \n",
    "                        correctness_counts.get('CORRECT_SUBOPTIMAL', 0)) / total_puzzles) * 100\n",
    "        \n",
    "        report['optimal_rate'] = optimal_rate\n",
    "        report['correct_rate'] = correct_rate\n",
    "        \n",
    "        # Progress analysis\n",
    "        report['average_progress'] = results_df['progress_score'].mean()\n",
    "        report['median_progress'] = results_df['progress_score'].median()\n",
    "        \n",
    "        # Efficiency analysis (for correct solutions)\n",
    "        correct_solutions = results_df[results_df['is_solved'] == True]\n",
    "        if len(correct_solutions) > 0:\n",
    "            report['average_efficiency'] = correct_solutions['efficiency'].mean()\n",
    "            report['median_efficiency'] = correct_solutions['efficiency'].median()\n",
    "        \n",
    "        # By model (if multiple models)\n",
    "        if 'model' in results_df.columns:\n",
    "            model_performance = results_df.groupby('model').agg({\n",
    "                'correctness': lambda x: (x == 'OPTIMAL').sum(),\n",
    "                'is_solved': 'sum',\n",
    "                'progress_score': 'mean',\n",
    "                'efficiency': 'mean'\n",
    "            }).round(3)\n",
    "            report['model_performance'] = model_performance.to_dict()\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def plot_results(self, results_df: pd.DataFrame, save_path: str = None):\n",
    "        \"\"\"Create visualization of results\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Correctness distribution\n",
    "        correctness_order = ['OPTIMAL', 'CORRECT_SUBOPTIMAL', 'PARTIAL_GOOD', 'PARTIAL_POOR', 'INVALID']\n",
    "        correctness_counts = results_df['correctness'].value_counts()\n",
    "        axes[0, 0].bar(range(len(correctness_counts)), \n",
    "                      [correctness_counts.get(level, 0) for level in correctness_order])\n",
    "        axes[0, 0].set_xticks(range(len(correctness_order)))\n",
    "        axes[0, 0].set_xticklabels(correctness_order, rotation=45)\n",
    "        axes[0, 0].set_title('Solution Correctness Distribution')\n",
    "        axes[0, 0].set_ylabel('Count')\n",
    "        \n",
    "        # Progress score distribution\n",
    "        axes[0, 1].hist(results_df['progress_score'], bins=20, alpha=0.7)\n",
    "        axes[0, 1].set_title('Progress Score Distribution')\n",
    "        axes[0, 1].set_xlabel('Progress Score')\n",
    "        axes[0, 1].set_ylabel('Count')\n",
    "        \n",
    "        # Efficiency vs Progress\n",
    "        axes[1, 0].scatter(results_df['progress_score'], results_df['efficiency'], alpha=0.6)\n",
    "        axes[1, 0].set_xlabel('Progress Score')\n",
    "        axes[1, 0].set_ylabel('Efficiency (moves/optimal)')\n",
    "        axes[1, 0].set_title('Efficiency vs Progress')\n",
    "        axes[1, 0].set_ylim(0, 5)  # Cap efficiency for readability\n",
    "        \n",
    "        # Model comparison (if multiple models)\n",
    "        if 'model' in results_df.columns and results_df['model'].nunique() > 1:\n",
    "            model_success = results_df.groupby('model')['is_solved'].mean()\n",
    "            axes[1, 1].bar(model_success.index, model_success.values)\n",
    "            axes[1, 1].set_title('Success Rate by Model')\n",
    "            axes[1, 1].set_ylabel('Success Rate')\n",
    "            axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            # Show move count distribution instead\n",
    "            valid_results = results_df[results_df['moves_found'] > 0]\n",
    "            axes[1, 1].hist(valid_results['moves_found'], bins=15, alpha=0.7)\n",
    "            axes[1, 1].set_title('Move Count Distribution')\n",
    "            axes[1, 1].set_xlabel('Number of Moves')\n",
    "            axes[1, 1].set_ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage functions\n",
    "def create_sample_responses():\n",
    "    \"\"\"Create sample responses for testing\"\"\"\n",
    "    sample_responses = {\n",
    "        \"puzzle1\": {\n",
    "            \"gpt4\": \"\"\"\n",
    "            Looking at this puzzle, I need to move the car C to the target position.\n",
    "            \n",
    "            <solution>\n",
    "            Step 1: B1 [1,2] -> [1,1]\n",
    "            Step 2: C [2,1] -> [1,1]\n",
    "            Step 3: C [1,1] -> [1,2]\n",
    "            </solution>\n",
    "            \"\"\",\n",
    "            \"claude\": \"\"\"\n",
    "            I'll solve this step by step:\n",
    "            \n",
    "            <solution>\n",
    "            Step 1: B1 [1,2] -> [2,2]\n",
    "            Step 2: C [2,1] -> [1,1] \n",
    "            Step 3: C [1,1] -> [1,2]\n",
    "            Step 4: C [1,2] -> [1,3]\n",
    "            </solution>\n",
    "            \"\"\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('sample_responses.json', 'w') as f:\n",
    "        json.dump(sample_responses, f, indent=2)\n",
    "    \n",
    "    return 'sample_responses.json'\n",
    "\n",
    "def main_evaluation_example():\n",
    "    \"\"\"Example of how to use the evaluator\"\"\"\n",
    "    \n",
    "    # Initialize evaluator\n",
    "    evaluator = RushHourEvaluator(dataset_path=\"data\")\n",
    "    \n",
    "    # Create sample responses for testing\n",
    "    responses_file = create_sample_responses()\n",
    "    \n",
    "    # Evaluate all responses\n",
    "    results_df = evaluator.evaluate_dataset(responses_file)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(results_df[['puzzle', 'model', 'correctness', 'progress_score', 'efficiency']])\n",
    "    \n",
    "    # Generate report\n",
    "    report = evaluator.generate_report(results_df)\n",
    "    print(\"\\nEvaluation Report:\")\n",
    "    for key, value in report.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    evaluator.plot_results(results_df, save_path=\"evaluation_results.png\")\n",
    "    \n",
    "    return results_df, report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results_df, report = main_evaluation_example()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
